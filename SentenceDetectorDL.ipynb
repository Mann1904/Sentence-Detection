{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SentenceDetectorDL.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8h1ee-GaEsn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "f982b427-0083-48b1-ac42-3b3bb0c0f73e"
      },
      "source": [
        "import os\n",
        "\n",
        "# Install java\n",
        "! apt-get update -qq\n",
        "! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
        "\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n",
        "! java -version\n",
        "\n",
        "# Install pyspark\n",
        "! pip install --ignore-installed -q pyspark==2.4.4\n",
        "! pip install --ignore-installed -q spark-nlp==2.6.3-rc1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "openjdk version \"1.8.0_265\"\n",
            "OpenJDK Runtime Environment (build 1.8.0_265-8u265-b01-0ubuntu2~18.04-b01)\n",
            "OpenJDK 64-Bit Server VM (build 25.265-b01, mixed mode)\n",
            "\u001b[K     |████████████████████████████████| 215.7MB 59kB/s \n",
            "\u001b[K     |████████████████████████████████| 204kB 45.2MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 133kB 2.8MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jirVPUT0F9bB"
      },
      "source": [
        "# SentenceDetectorDL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adrTGL-6ECtF"
      },
      "source": [
        "`bg Bulgarian`\n",
        "\n",
        "`bs Bosnian`\n",
        "\n",
        "`de German`\n",
        "\n",
        "`el Greek`\n",
        "\n",
        "`en English`\n",
        "\n",
        "`hr Croatian`\n",
        "\n",
        "`mk Macedonian`\n",
        "\n",
        "`ro Romanian`\n",
        "\n",
        "`sq Albanian`\n",
        "\n",
        "`sr Serbian`\n",
        "\n",
        "`tr Turkish`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_cR3Syj8wTd"
      },
      "source": [
        "from pyspark.ml import PipelineModel\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.base import *\n",
        "import sparknlp\n",
        "\n",
        "spark = sparknlp.start()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zS46q8E0Aidy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "5deaf10d-4871-4e05-9a6a-5cddd2f9bcc4"
      },
      "source": [
        "documenter = DocumentAssembler()\\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"document\")\n",
        "    \n",
        "sentencerDL = SentenceDetectorDLModel\\\n",
        "  .pretrained(\"sentence_detector_dl\", \"en\") \\\n",
        "  .setInputCols([\"document\"]) \\\n",
        "  .setOutputCol(\"sentences\")\n",
        "\n",
        "sd_pipeline = PipelineModel(stages=[documenter, sentencerDL])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sentence_detector_dl download started this may take some time.\n",
            "Approximate size to download 307.2 KB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHWj4IxqBnwK"
      },
      "source": [
        "sd_model = LightPipeline(sd_pipeline)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBJqnxE6-1uz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "3d8f1b1b-fcb3-4197-d847-1ba077a74c88"
      },
      "source": [
        "text = \"\"\"John loves Mary.Mary loves Peter\n",
        "Peter loves Helen .Helen loves John; \n",
        "Total: four people involved.\"\"\"\n",
        "\n",
        "for anno in sd_model.fullAnnotate(text)[0][\"sentences\"]:\n",
        "    print(\"{}\\t{}\\t{}\\t{}\".format(\n",
        "        anno.metadata[\"sentence\"], anno.begin, anno.end, anno.result))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\t0\t15\tJohn loves Mary.\n",
            "1\t16\t32\tMary loves Peter\n",
            "2\t33\t51\tPeter loves Helen .\n",
            "3\t52\t68\tHelen loves John;\n",
            "4\t71\t98\tTotal: four people involved.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ihAtVvIDSJh"
      },
      "source": [
        "### Testing with a broken text (random `\\n` chars added)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzRiZYqiCX4t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "c6ac9916-c38c-4393-c2e1-f0cc8ebc9850"
      },
      "source": [
        "text = '''\n",
        "There are many NLP tasks like text summarization, question-answering, sentence prediction to name a few. One method to get\\n these tasks done is using a pre-trained model. Instead of training \n",
        "a model from scratch for NLP tasks using millions of annotated texts each time, a general language representation is created by training a model on a huge amount of data. This is called a pre-trained model. This pre-trained model is \n",
        "then fine-tuned for each NLP tasks according to need.\n",
        "Let’s just peek into the pre-BERT world…\n",
        "For creating models, we need words to be represented in a form \\n understood by the training network, ie, numbers. Thus many algorithms were used to convert words into vectors or more precisely, word embeddings. \n",
        "One of the earliest algorithms used for this purpose is word2vec. However, the drawback of word2vec models was that they were context-free. One problem caused by this is that they cannot accommodate polysemy. For example, the word ‘letter’ has a different meaning according to the context. It can mean ‘single element of alphabet’ or ‘document addressed to another person’. But in word2vec both the letter returns same embeddings.\n",
        "'''\n",
        "\n",
        "for anno in sd_model.fullAnnotate(text)[0][\"sentences\"]:\n",
        "  \n",
        "    print(\"{}\\t{}\\t{}\\t{}\".format(\n",
        "        anno.metadata[\"sentence\"], anno.begin, anno.end, anno.result.replace('\\n',''))) # removing \\n to beutify printing\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\t1\t104\tThere are many NLP tasks like text summarization, question-answering, sentence prediction to name a few.\n",
            "1\t106\t170\tOne method to get these tasks done is using a pre-trained model.\n",
            "2\t172\t362\tInstead of training a model from scratch for NLP tasks using millions of annotated texts each time, a general language representation is created by training a model on a huge amount of data.\n",
            "3\t364\t398\tThis is called a pre-trained model.\n",
            "4\t400\t479\tThis pre-trained model is then fine-tuned for each NLP tasks according to need.\n",
            "5\t481\t521\tLet’s just peek into the pre-BERT world…\n",
            "6\t522\t634\tFor creating models, we need words to be represented in a form  understood by the training network, ie, numbers.\n",
            "7\t636\t731\tThus many algorithms were used to convert words into vectors or more precisely, word embeddings.\n",
            "8\t734\t798\tOne of the earliest algorithms used for this purpose is word2vec.\n",
            "9\t800\t872\tHowever, the drawback of word2vec models was that they were context-free.\n",
            "10\t874\t941\tOne problem caused by this is that they cannot accommodate polysemy.\n",
            "11\t943\t1022\tFor example, the word ‘letter’ has a different meaning according to the context.\n",
            "12\t1024\t1106\tIt can mean ‘single element of alphabet’ or ‘document addressed to another person’.\n",
            "13\t1108\t1163\tBut in word2vec both the letter returns same embeddings.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1uBCqrnElmi"
      },
      "source": [
        "## Compare with Spacy Sentence Splitter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsxT_2ulEspv"
      },
      "source": [
        "!pip install spacy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tHHalKGEoTu"
      },
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euCxCFU-Erpv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "d1820486-31df-4c75-8e20-24075ce633aa"
      },
      "source": [
        "text = \"\"\"John loves Mary.Mary loves Peter\n",
        "Peter loves Helen .Helen loves John; \n",
        "Total: four people involved.\"\"\"\n",
        "\n",
        "for sent in nlp(text).sents:\n",
        "    print(sent)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "John loves Mary.\n",
            "Mary loves Peter\n",
            "\n",
            "Peter loves Helen .Helen\n",
            "loves John; \n",
            "Total: four people involved.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rq1LuycdbpAf"
      },
      "source": [
        "## Test with another random broken sentence "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6EUTjAlFFVd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "outputId": "bab7a18f-076e-4d44-84ce-2246c33da94a"
      },
      "source": [
        "random_broken_text = '''\n",
        "A California woman who vanished in Utah’s Zion National Park earlier \n",
        "this month was found and reunited with her family, \n",
        "officials said Sunday. Holly Suzanne Courtier, 38, was located within the park after a visitor \n",
        "saw her and alerted rangers, the National Park Service said in a statement.\n",
        "Additional details about how she \n",
        "survived or where she was found were not immediately available. In the statement, Courtier’s relatives said they were “overjoyed” that she’d been found.\n",
        "Courtier, of Los Angeles, disappeared after a private shuttle dropped her off on Oct. 6 at the Grotto park area \n",
        "inside the 232-square-mile national park. She was scheduled to be picked up later that \n",
        "afternoon but didn't show up, park officials said. The search included K-9 units and federal, \n",
        "state and local rescue teams. Volunteers also joined the effort.\n",
        "'''\n",
        "\n",
        "print ('with Spark NLP SentenceDetectorDL')\n",
        "print ('===================================')\n",
        "\n",
        "for anno in sd_model.fullAnnotate(random_broken_text)[0][\"sentences\"]:\n",
        "  \n",
        "    print(\"{}\\t{}\".format(\n",
        "        anno.metadata[\"sentence\"], anno.result.replace('\\n',''))) # removing \\n to beutify printing\n",
        "\n",
        "print()\n",
        "print ('with Spacy Sentence Detection')\n",
        "print ('===================================')\n",
        "for i,sent in enumerate(nlp(random_broken_text).sents):\n",
        "    print(i, '\\t',str(sent).replace('\\n',''))# removing \\n to beutify printing"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "with Spark NLP SentenceDetectorDL\n",
            "===================================\n",
            "0\tA California woman who vanished in Utah’s Zion National Park earlier this month was found and reunited with her family, officials said Sunday.\n",
            "1\tHolly Suzanne Courtier, 38, was located within the park after a visitor saw her and alerted rangers, the National Park Service said in a statement.\n",
            "2\tAdditional details about how she survived or where she was found were not immediately available.\n",
            "3\tIn the statement, Courtier’s relatives said they were “overjoyed” that she’d been found.\n",
            "4\tCourtier, of Los Angeles, disappeared after a private shuttle dropped her off on Oct. 6 at the Grotto park area inside the 232-square-mile national park.\n",
            "5\tShe was scheduled to be picked up later that afternoon but didn't show up, park officials said.\n",
            "6\tThe search included K-9 units and federal, state and local rescue teams.\n",
            "7\tVolunteers also joined the effort.\n",
            "\n",
            "with Spacy Sentence Detection\n",
            "===================================\n",
            "0 \t A California woman who vanished in Utah’s Zion National Park\n",
            "1 \t earlier this month was found and reunited with her family, officials said Sunday.\n",
            "2 \t Holly Suzanne Courtier, 38, was located within the park after a visitor saw her and alerted rangers, the National Park Service said in a statement.\n",
            "3 \t Additional details about how she survived or where she was found were not immediately available.\n",
            "4 \t In the statement, Courtier’s relatives said they were “overjoyed” that she’d been found.\n",
            "5 \t Courtier, of Los Angeles, disappeared after a private shuttle dropped her off on Oct. 6 at the Grotto park area inside the 232-square-mile national park.\n",
            "6 \t She was scheduled to be picked up later\n",
            "7 \t that afternoon\n",
            "8 \t but didn't show up, park officials said.\n",
            "9 \t The search included K-9 units and federal, state and local rescue teams.\n",
            "10 \t Volunteers also joined the effort.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WiU0yHsvmxSv"
      },
      "source": [
        "## Multilanguage Sentence Detector DL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULFgE7KmkbMa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "c3443df2-908f-4bf8-eebd-a2cb49b95551"
      },
      "source": [
        "sentencerDL_multilang = SentenceDetectorDLModel\\\n",
        "  .pretrained(\"sentence_detector_dl\", \"xx\") \\\n",
        "  .setInputCols([\"document\"]) \\\n",
        "  .setOutputCol(\"sentences\")\n",
        "\n",
        "sd_pipeline_multi = PipelineModel(stages=[documenter, sentencerDL_multilang])\n",
        "\n",
        "sd_model_multi = LightPipeline(sd_pipeline_multi)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sentence_detector_dl download started this may take some time.\n",
            "Approximate size to download 612.8 KB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPR4MqEZbPo7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "outputId": "943d3f97-ea7f-4850-d824-176983836929"
      },
      "source": [
        "gr_text= '''\n",
        "Όπως ίσως θα γνωρίζει, όταν εγκαθιστάς μια νέα εφαρμογή, θα έχεις διαπιστώσει \n",
        "λίγο μετά, ότι το PC αρχίζει να επιβραδύνεται. Στη συνέχεια, όταν επισκέπτεσαι την οθόνη ή από την διαχείριση εργασιών, θα διαπιστώσεις ότι η εν λόγω εφαρμογή έχει προστεθεί στη \n",
        "λίστα των προγραμμάτων που εκκινούν αυτόματα, όταν ξεκινάς το PC.\n",
        "Προφανώς, κάτι τέτοιο δεν αποτελεί μια ιδανική κατάσταση, ιδίως για τους λιγότερο γνώστες, οι \n",
        "οποίοι ίσως δεν θα συνειδητοποιήσουν ότι κάτι τέτοιο συνέβη. Όσο περισσότερες εφαρμογές στη λίστα αυτή, τόσο πιο αργή γίνεται η \n",
        "εκκίνηση, ιδίως αν πρόκειται για απαιτητικές εφαρμογές. Τα ευχάριστα νέα είναι ότι η τελευταία και πιο πρόσφατη preview build της έκδοσης των Windows 10 που θα καταφθάσει στο πρώτο μισό του 2021, οι εφαρμογές θα \n",
        "ενημερώνουν το χρήστη ότι έχουν προστεθεί στη λίστα των εφαρμογών που εκκινούν μόλις ανοίγεις το PC.\n",
        "'''\n",
        "\n",
        "print ('with Spark NLP SentenceDetectorDL')\n",
        "print ('===================================')\n",
        "\n",
        "for anno in sd_model_multi.fullAnnotate(gr_text)[0][\"sentences\"]:\n",
        "  \n",
        "    print(\"{}\\t{}\".format(\n",
        "        anno.metadata[\"sentence\"], anno.result.replace('\\n',''))) # removing \\n to beutify printing\n",
        "\n",
        "print()\n",
        "print ('with Spacy Sentence Detection')\n",
        "print ('===================================')\n",
        "for i,sent in enumerate(nlp(gr_text).sents):\n",
        "    print(i, '\\t',str(sent).replace('\\n',''))# removing \\n to beutify printing"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "with Spark NLP SentenceDetectorDL\n",
            "===================================\n",
            "0\tΌπως ίσως θα γνωρίζει, όταν εγκαθιστάς μια νέα εφαρμογή, θα έχεις διαπιστώσει λίγο μετά, ότι το PC αρχίζει να επιβραδύνεται.\n",
            "1\tΣτη συνέχεια, όταν επισκέπτεσαι την οθόνη ή από την διαχείριση εργασιών, θα διαπιστώσεις ότι η εν λόγω εφαρμογή έχει προστεθεί στη λίστα των προγραμμάτων που εκκινούν αυτόματα, όταν ξεκινάς το PC.\n",
            "2\tΠροφανώς, κάτι τέτοιο δεν αποτελεί μια ιδανική κατάσταση, ιδίως για τους λιγότερο γνώστες, οι οποίοι ίσως δεν θα συνειδητοποιήσουν ότι κάτι τέτοιο συνέβη.\n",
            "3\tΌσο περισσότερες εφαρμογές στη λίστα αυτή, τόσο πιο αργή γίνεται η εκκίνηση, ιδίως αν πρόκειται για απαιτητικές εφαρμογές.\n",
            "4\tΤα ευχάριστα νέα είναι ότι η τελευταία και πιο πρόσφατη preview build της έκδοσης των Windows 10 που θα καταφθάσει στο πρώτο μισό του 2021, οι εφαρμογές θα ενημερώνουν το χρήστη ότι έχουν προστεθεί στη λίστα των εφαρμογών που εκκινούν μόλις ανοίγεις το PC.\n",
            "\n",
            "with Spacy Sentence Detection\n",
            "===================================\n",
            "0 \t Όπως ίσως θα γνωρίζει, όταν εγκαθιστάς μια\n",
            "1 \t νέα εφαρμογή, θα έχεις διαπιστώσει \n",
            "2 \t λίγο μετά, ότι το\n",
            "3 \t PC αρχίζει να επιβραδύνεται.\n",
            "4 \t Στη συνέχεια, όταν επισκέπτεσαι την οθόνη ή\n",
            "5 \t από την διαχείριση εργασιών, θα διαπιστώσεις ότι η εν λόγω εφαρμογή έχει προστεθεί στη \n",
            "6 \t λίστα των\n",
            "7 \t προγραμμάτων που εκκινούν αυτόματα, όταν ξεκινάς το PC.\n",
            "8 \t Προφανώς, κάτι τέτοιο δεν αποτελεί μια ιδανική κατάσταση, ιδίως για τους λιγότερο γνώστες, οι \n",
            "9 \t οποίοι ίσως δεν θα συνειδητοποιήσουν ότι κάτι τέτοιο συνέβη.\n",
            "10 \t Όσο περισσότερες εφαρμογές στη λίστα αυτή, τόσο πιο αργή γίνεται η εκκίνηση, ιδίως αν πρόκειται για απαιτητικές εφαρμογές.\n",
            "11 \t Τα ευχάριστα νέα είναι ότι η τελευταία και πιο πρόσφατη preview build της έκδοσης των Windows 10\n",
            "12 \t που\n",
            "13 \t θα καταφθάσει\n",
            "14 \t στο πρώτο μισό του 2021, οι εφαρμογές\n",
            "15 \t θα ενημερώνουν το χρήστη ότι\n",
            "16 \t έχουν προστεθεί στη λίστα\n",
            "17 \t των εφαρμογών που εκκινούν μόλις ανοίγεις το PC.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUc7n1wsktJs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 762
        },
        "outputId": "17f60724-614b-4e59-ed48-142757b464b0"
      },
      "source": [
        "cyrillic_text = '''\n",
        "B чeтвъpтъĸ Gооglе oбяви няĸoлĸo aĸтyaлизaции нa cвoятa тъpcaчĸa, зaявявaйĸи чe e \n",
        "въвeлa изĸycтвeн интeлeĸт (Аl) и мaшиннo oбyчeниe зa пoдoбpявaнe нa пoтpeбитeлcĸoтo изживявaнe.\n",
        "Πoтpeбитeлитe вeчe мoгaт дa cи тaнaниĸaт, cвиpят или пeят мeлoдия нa пeceн нa Gооglе чpeз мoбилнoтo пpилoжeниe, \n",
        "ĸaтo дoĸocнaт иĸoнaтa нa миĸpoфoнa и зaдaдaт въпpoca: Koя e тaзи пeceн?\n",
        "Taнaниĸaнeтo в пpoдължeниe нa 10-15 ceĸyнди щe дaдe шaнc нa aлгopитъмa c мaшиннo oбyчeниe нa Gооglе дa нaмepи и извeдe peзyлтaт ĸoя e пpипявaнaтa пeceн.\n",
        "Πoнacтoящeм фyнĸциятa e дocтъпнa нa aнглийcĸи eзиĸ зa Іоѕ и нa oĸoлo 20 eзиĸa зa Аndrоіd, \n",
        "ĸaтo в бъдeщe и зa двeтe oпepaциoнни cиcтeми щe бъдe пpeдлoжeн eднaĸъв нaбop oт пoддъpжaни eзици, ĸaзвaт oт Gооglе.\n",
        "Al aĸтyaлизaциитe нa тъpceщия гигaнт cъщo oбxвaщaт пpaвoпиca и oбщитe зaявĸи зa тъpceнe.\n",
        "Cpeд пoдoбpeниятa e вĸлючeн нoв пpaвoпиceн aлгopитъм, ĸoйтo изпoлзвa нeвpoннa мpeжa \n",
        "c дълбoĸo oбyчeниe, зa ĸoятo Gооglе твъpди, чe идвa cъc знaчитeлнo пoдoбpeнa cпocoбнocт зa \n",
        "дeшифpиpaнe нa пpaвoпиcни гpeшĸи.\n",
        "'''\n",
        "\n",
        "print ('with Spark NLP SentenceDetectorDL')\n",
        "print ('===================================')\n",
        "\n",
        "for anno in sd_model_multi.fullAnnotate(cyrillic_text)[0][\"sentences\"]:\n",
        "  \n",
        "    print(\"{}\\t{}\".format(\n",
        "        anno.metadata[\"sentence\"], anno.result.replace('\\n',''))) # removing \\n to beutify printing\n",
        "\n",
        "print()\n",
        "print ('with Spacy Sentence Detection')\n",
        "print ('===================================')\n",
        "for i,sent in enumerate(nlp(cyrillic_text).sents):\n",
        "    print(i, '\\t',str(sent).replace('\\n',''))# removing \\n to beutify printing"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "with Spark NLP SentenceDetectorDL\n",
            "===================================\n",
            "0\tB чeтвъpтъĸ Gооglе oбяви няĸoлĸo aĸтyaлизaции нa cвoятa тъpcaчĸa, зaявявaйĸи чe e въвeлa изĸycтвeн интeлeĸт (Аl) и мaшиннo oбyчeниe зa пoдoбpявaнe нa пoтpeбитeлcĸoтo изживявaнe.\n",
            "1\tΠoтpeбитeлитe вeчe мoгaт дa cи тaнaниĸaт, cвиpят или пeят мeлoдия нa пeceн нa Gооglе чpeз мoбилнoтo пpилoжeниe, ĸaтo дoĸocнaт иĸoнaтa нa миĸpoфoнa и зaдaдaт въпpoca: Koя e тaзи пeceн?\n",
            "2\tTaнaниĸaнeтo в пpoдължeниe нa 10-15 ceĸyнди щe дaдe шaнc нa aлгopитъмa c мaшиннo oбyчeниe нa Gооglе дa нaмepи и извeдe peзyлтaт ĸoя e пpипявaнaтa пeceн.\n",
            "3\tΠoнacтoящeм фyнĸциятa e дocтъпнa нa aнглийcĸи eзиĸ зa Іоѕ и нa oĸoлo 20 eзиĸa зa Аndrоіd, ĸaтo в бъдeщe и зa двeтe oпepaциoнни cиcтeми щe бъдe пpeдлoжeн eднaĸъв нaбop oт пoддъpжaни eзици, ĸaзвaт oт Gооglе.\n",
            "4\tAl aĸтyaлизaциитe нa тъpceщия гигaнт cъщo oбxвaщaт пpaвoпиca и oбщитe зaявĸи зa тъpceнe.\n",
            "5\tCpeд пoдoбpeниятa e вĸлючeн нoв пpaвoпиceн aлгopитъм, ĸoйтo изпoлзвa нeвpoннa мpeжa c дълбoĸo oбyчeниe, зa ĸoятo Gооglе твъpди, чe идвa cъc знaчитeлнo пoдoбpeнa cпocoбнocт зa дeшифpиpaнe нa пpaвoпиcни гpeшĸи.\n",
            "\n",
            "with Spacy Sentence Detection\n",
            "===================================\n",
            "0 \t B чeтвъpтъĸ Gооglе oбяви няĸoлĸo aĸтyaлизaции нa cвoятa тъpcaчĸa, зaявявaйĸи чe e въвeлa изĸycтвeн интeлeĸт (\n",
            "1 \t Аl) и мaшиннo oбyчeниe\n",
            "2 \t зa пoдoбpявaнe нa пoтpeбитeлcĸoтo изживявaнe.\n",
            "3 \t Πoтpeбитeлитe вeчe мoгaт дa\n",
            "4 \t cи тaнaниĸaт, cвиpят или пeят мeлoдия нa пeceн нa Gооglе чpeз мoбилнoтo пpилoжeниe, \n",
            "5 \t ĸaтo\n",
            "6 \t дoĸocнaт иĸoнaтa\n",
            "7 \t нa миĸpoфoнa\n",
            "8 \t и зaдaдaт въпpoca:\n",
            "9 \t Koя e тaзи пeceн?\n",
            "10 \t Taнaниĸaнeтo в пpoдължeниe нa\n",
            "11 \t 10-15 ceĸyнди щe дaдe шaнc нa aлгopитъмa c мaшиннo oбyчeниe нa Gооglе\n",
            "12 \t дa нaмepи и извeдe peзyлтaт ĸoя e пpипявaнaтa пeceн.\n",
            "13 \t Πoнacтoящeм\n",
            "14 \t фyнĸциятa e\n",
            "15 \t дocтъпнa нa aнглийcĸи eзиĸ\n",
            "16 \t зa\n",
            "17 \t Іоѕ и нa oĸoлo 20 eзиĸa зa Аndrоіd, ĸaтo\n",
            "18 \t в бъдeщe и зa двeтe oпepaциoнни cиcтeми щe бъдe пpeдлoжeн\n",
            "19 \t eднaĸъв нaбop oт пoддъpжaни eзици, ĸaзвaт oт Gооglе.\n",
            "20 \t Al aĸтyaлизaциитe нa\n",
            "21 \t тъpceщия гигaнт\n",
            "22 \t cъщo oбxвaщaт пpaвoпиca\n",
            "23 \t и\n",
            "24 \t oбщитe зaявĸи\n",
            "25 \t зa тъpceнe.\n",
            "26 \t Cpeд пoдoбpeниятa e вĸлючeн нoв пpaвoпиceн aлгopитъм, ĸoйтo изпoлзвa нeвpoннa мpeжa \n",
            "27 \t c дълбoĸo oбyчeниe, зa\n",
            "28 \t ĸoятo Gооglе твъpди, чe идвa\n",
            "29 \t cъc знaчитeлнo пoдoбpeнa cпocoбнocт\n",
            "30 \t зa \n",
            "31 \t дeшифpиpaнe нa пpaвoпиcни гpeшĸи.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ssBZRBqmeg3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}